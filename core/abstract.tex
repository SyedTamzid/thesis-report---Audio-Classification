\section*{Abstract}
Sounds have a wealth of information that enhances our understanding in this unprejudiced world. Every day we face many sounds around us. From this sound we filter all sounds in our brain cell and provide with a result what sounds are fit in which dice. For this not only our brain cells many machines are also available. Working with sound classifications, can improve recommendations in various applications. To work properly these machines, need to know the right way to extract data from it. Digital audio has a lack of structured organizations. So that it brings significant complexity to sound classification work. Keeping that in mind we intended to do research in sound classification. The primary goal of our research is to find which feature fits our model and gives us maximum values that we desire for. All the while we will try to analyze different models to see which work more efficiently. Our plan is to collect speech command dataset from online sources. We intended to use deep learning methods to analyze our data in different features. Those features are MFCC, Mel Spectrogram, Wavelet. For our model we use conventional neural networks (CNN), long short-term memory (LTSM). Also, we will analyze raw data without implementing any features. 




\vspace{1cm}
\textbf{Keywords:}  convolutional neural networks (CNN), LSTM, Deep learning, Mel Frequency Cepstral Coefficient (MFCC), Wavelet. Mel-Spectrogram.
\pagebreak
